{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zhkM5ptWufTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ccf1c26-1572-4c9d-b95d-dfe4165adb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIbxkftOz-22",
        "outputId": "08f91310-6c6b-4fe0-f0ed-c978ec608e68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset**"
      ],
      "metadata": {
        "id": "Ms9lEFrT4FEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/content/IMDB Dataset.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa28Mn0O0HdW",
        "outputId": "ff6e633e-1190-482b-ca08-46a115fb05ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cleaning Review**"
      ],
      "metadata": {
        "id": "9nT6q-wI4Lkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "if 'review' not in df.columns:\n",
        "    raise KeyError(\"The dataset does not contain a 'review' column. Please check the column names.\")\n",
        "\n",
        "# Function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    return words\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "    # Tokenization\n",
        "    words = tokenize_text(text)\n",
        "    # Stopword removal, stemming, and lemmatization\n",
        "    words = [lemmatizer.lemmatize(ps.stem(word)) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "print(df[['review', 'cleaned_review']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2p_Vqci0LKL",
        "outputId": "1c8db46e-39fe-423e-a1f8-146a6cde849a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  \\\n",
            "0  One of the other reviewers has mentioned that ...   \n",
            "1  A wonderful little production. <br /><br />The...   \n",
            "2  I thought this was a wonderful way to spend ti...   \n",
            "3  Basically there's a family where a little boy ...   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
            "\n",
            "                                      cleaned_review  \n",
            "0  one review mention watch oz episod youll hook ...  \n",
            "1  wonder littl product br br film techniqu unass...  \n",
            "2  thought wonder way spend time hot summer weeke...  \n",
            "3  basic there famili littl boy jake think there ...  \n",
            "4  petter mattei love time money visual stun film...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mapping Sentiment**"
      ],
      "metadata": {
        "id": "vIA8SE9i4SmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_sentiment(sentiment):\n",
        "    return 1 if sentiment == \"positive\" else 0\n",
        "df['sentiment'] = df['sentiment'].apply(map_sentiment)\n"
      ],
      "metadata": {
        "id": "Sw5tVS-w0NQ-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training ML Models**"
      ],
      "metadata": {
        "id": "WmVA9D4W4ZMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['sentiment'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cM1maQ--0WpU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "tdDV07Yr0bHj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, model_name):\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "jb6d7J3-0eQx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **LogisticRegression**"
      ],
      "metadata": {
        "id": "FOi29kbL4gqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "train_and_evaluate(lr_model, \"Logistic Regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1BzvqjV0hy6",
        "outputId": "bf4180fb-c1ac-4ec9-dfb0-0f91495dba75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.8853, F1-score: 0.8879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "kLk4n6Zs4oSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = MultinomialNB()\n",
        "train_and_evaluate(nb_model, \"Naïve Bayes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRNPvirH0mQV",
        "outputId": "3d97429b-3129-4348-9cbd-912949e14587"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Bayes - Accuracy: 0.8469, F1-score: 0.8489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict Sentiment**"
      ],
      "metadata": {
        "id": "2CjklsHe4vTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review):\n",
        "    original_review = review\n",
        "    review = preprocess_text(review)\n",
        "    review_tfidf = vectorizer.transform([review])\n",
        "    prediction = lr_model.predict(review_tfidf)[0]\n",
        "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
        "    print(f\"Review: {original_review}\\nPredicted Sentiment: {sentiment}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x2NIQCo11qXv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User Input**"
      ],
      "metadata": {
        "id": "Wpm1ud6740jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_review = \"This movie was fantastic! The acting was great.\"\n",
        "predict_sentiment(user_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM-sEMoW2yUJ",
        "outputId": "0ba41c07-deba-40f5-a365-2409147af7d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: This movie was fantastic! The acting was great.\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ]
    }
  ]
}